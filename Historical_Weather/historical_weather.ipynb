{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time, csv, requests, os\n",
    "from config import google_api_key\n",
    "from config import visual_rapid_api_key\n",
    "from natl_parks import us_natl_parks\n",
    "\n",
    "# Incorporated citipy to determine city based on latitude and longitude\n",
    "from citipy import citipy\n",
    "\n",
    "# Lists for data cleaning\n",
    "from city_states import format_us_states\n",
    "from states_per_park import states_by_park\n",
    "\n",
    "# Consolidate CSVs into one CSV\n",
    "from names_of_csvs import all_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = google_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coor(park, API_KEY):\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?\"\n",
    "    payload = {\n",
    "        \"key\" : API_KEY,\n",
    "        \"input\" : park,\n",
    "        \"inputtype\" : \"textquery\",\n",
    "        \"fields\" : \"name,place_id,geometry/location,formatted_address\"\n",
    "    }\n",
    "    r = requests.get(url, params = payload)\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        return r.json()\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "all_park_info = []\n",
    "for park in us_natl_parks:\n",
    "    result = get_coor(park, API_KEY)\n",
    "    if result:\n",
    "        all_park_info.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = []\n",
    "longitude = []\n",
    "park = []\n",
    "states = []\n",
    "\n",
    "for row in all_park_info:\n",
    "    latitude.append(row[\"candidates\"][0][\"geometry\"][\"location\"][\"lat\"])\n",
    "    longitude.append(row[\"candidates\"][0][\"geometry\"][\"location\"][\"lng\"])\n",
    "    park.append(row['candidates'][0]['name'])\n",
    "    states.append(row['candidates'][0]['formatted_address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Latitude\":latitude,\n",
    "    \"Longitude\":longitude,\n",
    "    \"Park\": park\n",
    "})\n",
    "\n",
    "df.to_csv(\"Park Coordinates.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = visual_rapid_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert types, zip lat and long to create coordinates\n",
    "lat_lngs = []\n",
    "latitude = df[\"Latitude\"].tolist()\n",
    "longitude = df[\"Longitude\"].tolist()\n",
    "lat_lngs = zip(latitude, longitude)\n",
    "\n",
    "# Identify nearest city for each coordinate\n",
    "cities = []\n",
    "for lat_lng in lat_lngs:\n",
    "    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name\n",
    "    \n",
    "    # If the city is unique, then add it to our cities list\n",
    "    if city not in cities:\n",
    "        cities.append(city)\n",
    "\n",
    "# Complete list where citipy unable to assign\n",
    "cities.insert(8, \"moab\")\n",
    "cities.insert(28, \"pine springs\")\n",
    "cities.insert(38, \"kiana\")\n",
    "cities.insert(58, \"mccarthy\")\n",
    "cities.insert(59, \"canyon village\")\n",
    "# Swap citipy British selection for US city\n",
    "cities1 = [\"coral bay\" if x == \"road town\"  else x for x in cities]\n",
    "# Swap citipy Mexico selection for US city\n",
    "cities2 = [\"terlingua\" if x == \"ojinaga\"  else x for x in cities1]\n",
    "\n",
    "# Concatenate Nearest City to State\n",
    "concat_func = lambda x,y: x + \",\" + str(y)\n",
    "nearest_city_and_state = list(map(concat_func, cities2, states_by_park))\n",
    "\n",
    "# Use dictionary comprehension to convert lists to dictionary (to run loop through values)\n",
    "states_dict = {states[i]: nearest_city_and_state[i] for i in range(len(states))}\n",
    "\n",
    "#Create function to request historical weather by Nearest City and State\n",
    "def hist_weather(value, API_KEY):\n",
    "    f = open(str(value)+\".csv\",\"w+\")\n",
    "    \n",
    "    url = \"https://visual-crossing-weather.p.rapidapi.com/history\"\n",
    "\n",
    "    querystring = {\n",
    "        \"startDateTime\":\"2015-01-01T00:00:00\",\n",
    "        \"aggregateHours\":\"24\",\n",
    "        \"location\": value,\n",
    "        \"endDateTime\":\"2019-12-30T24:00:00\",\n",
    "        \"unitGroup\":\"us\"\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        'x-rapidapi-host': \"visual-crossing-weather.p.rapidapi.com\",\n",
    "        'x-rapidapi-key': API_KEY\n",
    "        }\n",
    "\n",
    "    r = requests.request(\"GET\", url, headers = headers, params = querystring)\n",
    "\n",
    "    if r:\n",
    "        final = r.text\n",
    "        f.write(final)\n",
    "        f.close()\n",
    "    else:\n",
    "        print(\"No historical weather available for \"+ str(value))\n",
    "        f.close()\n",
    "\n",
    "# Loop request for the Nearest City,State\n",
    "for value in states_dict.values():   \n",
    "    hist_weather(value, API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile CSVs into single CSV\n",
    "with open(\"his_weather_final.csv\", \"w\") as csv_file:\n",
    "    fileWriter = csv.writer(csv_file)\n",
    "    for place in all_csv:\n",
    "        file_to_load = os.path.join(place)\n",
    "        with open(file_to_load, \"r\") as weather_data:\n",
    "            fileReader = csv.reader(weather_data, delimiter = \",\")\n",
    "            # Skip Headers: address, Date time, Cloud Cover, Latitude, Longitude, Resolved Address\n",
    "            next(fileReader)\n",
    "            for row in fileReader:\n",
    "                fileWriter.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "darksky",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
